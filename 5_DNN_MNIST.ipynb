{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_DNN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbuSrUKDbMM4",
        "colab_type": "text"
      },
      "source": [
        "# Load Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p1ghSekbSWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "#tf.set_random_seed(42)\n",
        "tf.random.set_seed(55)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9XDv88RbbAf",
        "colab_type": "text"
      },
      "source": [
        "# Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxYHTOXxbddB",
        "colab_type": "code",
        "outputId": "d6a5871b-fc70-49ca-f1e8-cfb0e31c0647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#MNIST Data\n",
        "(trainX, trainY), (testX,testY)= tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgFMssbJbuq4",
        "colab_type": "code",
        "outputId": "735838b4-b8e0-4106-fec4-3121a54a055f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wVKplnLdtIE",
        "colab_type": "code",
        "outputId": "956e6a62-7179-4b35-fa2a-1080a1573c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfpSd4X8d2AJ",
        "colab_type": "code",
        "outputId": "43fa249e-3985-47bd-cf2d-62d74543a6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Number of labels\n",
        "trainY.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB7nHQP7d7lh",
        "colab_type": "code",
        "outputId": "11fad33b-fd53-47e1-9586-cae58170f54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testY.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsbCWvJMbwvA",
        "colab_type": "code",
        "outputId": "62786ea8-a31e-46b8-8964-773888fe12a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainX[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6NUInmbeDc5",
        "colab_type": "code",
        "outputId": "62f8f7ed-8fe7-4f9e-86f0-c95a2cbcf96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNJ2VPw4dFsH",
        "colab_type": "code",
        "outputId": "d936e62c-1b17-4675-af6c-9a32a38483f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# To print the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(trainX[0], cmap='gray')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fee933b42e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVqNB0PnfHt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hFuklRcftHH",
        "colab_type": "text"
      },
      "source": [
        "# Convert Output label to multiple values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tUAR2lvfwv-",
        "colab_type": "code",
        "outputId": "9ac4a129-4024-4b41-d604-affd7372d838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('Samples of trainY :', trainY[0:2])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "Samples of trainY : [5 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X5LVDc0f9g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryi7V0y_hFw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testY=tf.keras.utils.to_categorical(testY,num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDLvqAoahaPV",
        "colab_type": "code",
        "outputId": "f22b49c7-ae99-4375-c60f-beb653b9f47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print (trainY.shape)\n",
        "print('Samples of trainY :', trainY[0:2])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "Samples of trainY : [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNIQNHHUhjrj",
        "colab_type": "text"
      },
      "source": [
        "# Build the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R10CwdAOhmu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize Sequential Model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape the data from 2D to 1D -> 28x28 to 784\n",
        "# The equation accepts samples at vectors. Our current input is matrix\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bciygrNCWEC",
        "colab_type": "text"
      },
      "source": [
        "#Build DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vt8g8O0lBYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
        "\n",
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "\n",
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.Dense(60, activation='sigmoid'))\n",
        "\n",
        "#Add 4th hidden layer\n",
        "model.add(tf.keras.layers.Dense(30, activation='sigmoid'))\n",
        "\n",
        "#Add output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf9cMgH2Dg5c",
        "colab_type": "text"
      },
      "source": [
        "# Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upuyC6H2Dju0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mTRzQl5D5cU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7635b066-4b4a-4599-a9c5-54650b3499c1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 60)                6060      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 188,436\n",
            "Trainable params: 186,868\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnjWH2_EKSq",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1eN_JPIEMjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "644ccbb6-6690-47db-fa6e-3704d6721fc7"
      },
      "source": [
        "model.fit(trainX,trainY, \n",
        "          validataion_data=(testX,testY),\n",
        "          epochs=100,\n",
        "          batch_size=32)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3059 - accuracy: 0.1130\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2957 - accuracy: 0.1168\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2899 - accuracy: 0.1266\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2795 - accuracy: 0.1586\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2557 - accuracy: 0.2329\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1670 - accuracy: 0.3637\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8215 - accuracy: 0.4066\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4692 - accuracy: 0.4597\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3147 - accuracy: 0.5253\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2083 - accuracy: 0.5860\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0928 - accuracy: 0.6537\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9636 - accuracy: 0.7141\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8365 - accuracy: 0.7561\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.7395 - accuracy: 0.7892\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6560 - accuracy: 0.8182\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5883 - accuracy: 0.8391\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5300 - accuracy: 0.8556\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4845 - accuracy: 0.8677\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4492 - accuracy: 0.8777\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4260 - accuracy: 0.8826\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4046 - accuracy: 0.8867\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3856 - accuracy: 0.8925\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3737 - accuracy: 0.8953\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3613 - accuracy: 0.8989\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3480 - accuracy: 0.9028\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3360 - accuracy: 0.9054\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3253 - accuracy: 0.9077\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3143 - accuracy: 0.9127\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3030 - accuracy: 0.9141\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2921 - accuracy: 0.9171\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2835 - accuracy: 0.9197\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2758 - accuracy: 0.9233\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2654 - accuracy: 0.9260\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2542 - accuracy: 0.9283\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2449 - accuracy: 0.9315\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2335 - accuracy: 0.9348\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2282 - accuracy: 0.9368\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2205 - accuracy: 0.9378\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2120 - accuracy: 0.9409\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2036 - accuracy: 0.9434\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1967 - accuracy: 0.9454\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1879 - accuracy: 0.9475\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1826 - accuracy: 0.9497\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1759 - accuracy: 0.9515\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1697 - accuracy: 0.9531\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1638 - accuracy: 0.9550\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1573 - accuracy: 0.9568\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1513 - accuracy: 0.9581\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1470 - accuracy: 0.9598\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1427 - accuracy: 0.9597\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1388 - accuracy: 0.9619\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1329 - accuracy: 0.9635\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1298 - accuracy: 0.9643\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1245 - accuracy: 0.9663\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1204 - accuracy: 0.9670\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1184 - accuracy: 0.9671\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1142 - accuracy: 0.9685\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1101 - accuracy: 0.9696\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9708\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1037 - accuracy: 0.9704\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1009 - accuracy: 0.9719\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0969 - accuracy: 0.9728\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0940 - accuracy: 0.9738\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0916 - accuracy: 0.9749\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0888 - accuracy: 0.9746\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0874 - accuracy: 0.9761\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0830 - accuracy: 0.9770\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0828 - accuracy: 0.9775\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0776 - accuracy: 0.9786\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0760 - accuracy: 0.9789\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0759 - accuracy: 0.9794\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0730 - accuracy: 0.9801\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0708 - accuracy: 0.9803\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0683 - accuracy: 0.9806\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0662 - accuracy: 0.9814\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0641 - accuracy: 0.9822\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0633 - accuracy: 0.9829\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0616 - accuracy: 0.9830\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0587 - accuracy: 0.9842\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0583 - accuracy: 0.9838\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0578 - accuracy: 0.9835\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0563 - accuracy: 0.9843\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0529 - accuracy: 0.9858\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0541 - accuracy: 0.9847\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0509 - accuracy: 0.9863\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0494 - accuracy: 0.9864\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0481 - accuracy: 0.9867\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0468 - accuracy: 0.9874\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0470 - accuracy: 0.9874\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0454 - accuracy: 0.9878\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0433 - accuracy: 0.9887\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0428 - accuracy: 0.9881\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0416 - accuracy: 0.9890\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0401 - accuracy: 0.9893\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0412 - accuracy: 0.9890\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0388 - accuracy: 0.9894\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0382 - accuracy: 0.9900\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0376 - accuracy: 0.9899\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0368 - accuracy: 0.9901\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0357 - accuracy: 0.9906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee8c178f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIH6j76HGoMT",
        "colab_type": "text"
      },
      "source": [
        "#Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV_eDIEHExkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('mnist_dnn_v1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3aeoPu7IfF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('mnist_dnn_v1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXcDLBzCIn1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e373e55a-bf15-4166-8244-0005f42b5648"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 772\n",
            "-rw-r--r-- 1 root root 782744 Apr  9 08:49 mnist_dnn_v1.h5\n",
            "drwxr-xr-x 1 root root   4096 Apr  3 16:24 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}